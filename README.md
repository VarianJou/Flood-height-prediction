# Flood Height Prediction Research Project

This repository contains code and data for predicting flood heights using machine learning approaches.

## Project Overview

The project consists of three main components:
1. **Feature Extraction**: Extracts landscape and topographic features around flood locations
2. **Target Generation**: Calculates flood depths from elevation measurements  
3. **Machine Learning**: Uses data fusion and machine learning to predict flood depths

## Repository Structure

### Folders
- **`data/`** - Contains processed feature datasets and analysis outputs
- **`routing/`** - Machine learning routing algorithms and training pipelines
- **`.idea/`** - IDE configuration files (IntelliJ/PyCharm)

## Code Files Overview

| File | Last Updated | Description |
|------|-------------|-------------|
| **NLCD_Extract_v0.1.0.py** | 2025-08-06 | Main script for extracting NLCD impervious surface features around flood points. Creates 1.5km square buffers, processes multi-year data (2016-2024), calculates landscape metrics including area percentages and core area indices. |
| **NLCD_Extract_v0.1.0_test.ipynb** | 2025-08-06 | Jupyter notebook for testing and prototyping the NLCD extraction workflow. Contains experimental code and visualizations for buffer creation and metrics calculation. |
| **dem_features.ipynb** | 2025-08-06 | Jupyter notebook for extracting digital elevation model (DEM) features around flood points. Processes topographic characteristics and terrain metrics. |
| **Calculate_HWM_Depth_v1.0.ipynb** | 2025-08-06 | New Jupyter notebook for calculating High Water Mark (HWM) depth measurements. Processes flood depth data and generates target variable for machine learning models. |
| **routing/routing.py** | 2025-08-06 | Core routing functionality for multi-route neural network architecture. Defines feature routing mappings and data preparation pipelines for ML models. |
| **routing/gs_routes.py** | 2025-08-06 | Grid search implementation for testing all possible feature-route combinations in the routing classifier. Generates and evaluates different routing strategies. |
| **routing/training.py** | 2025-08-06 | Training pipeline for routing-based neural network models. Includes model training, validation, and dummy data generation functions. |
| **CLAUDE.md** | 2025-08-06 | Project documentation and guidance for Claude Code AI assistant. Contains architecture overview, dependencies, and development notes. |
| **README.md** | 2025-08-06 | This file - comprehensive project documentation including file descriptions, usage instructions, and technical details. |

### Major Changes Summary
- **v0.1.0 (Initial)**: Multi-year NLCD processing, buffer creation, landscape metrics
- **Recent Updates**: Added DEM feature extraction, routing-based ML architecture, improved error handling and CRS transformations
- **Latest (August 2025)**: Added HWM depth calculation notebook and target data for machine learning models

## Input and Output Files

### Input Data Sources

#### External Input Files (Not in Repository)
| File | Size | Used By | Source | Description |
|------|------|---------|--------|-------------|
| **filtered_flooding_points_over_one_day*.shp** | N/A | NLCD_Extract_v0.1.0.py, Calculate_HWM_Depth_v1.0.ipynb | USGS | High water mark points with ID, peak_date, elev_ft, and geometry attributes |
| **Annual_NLCD_ImpDsc_[YEAR]_CU_C1V1.tif** | ~4GB each | NLCD_Extract_v0.1.0.py | USGS National Land Cover Database | Annual impervious surface data (2016-2024), 30m resolution |
| **{ID}_USGS_3DEP_{YEAR}.tif** | Varies | Calculate_HWM_Depth_v1.0.ipynb, dem_features.ipynb | USGS 3DEP | Individual DEM raster files named by flood point ID and year, 10m resolution |
| **flooding_dataset_with_precipitation_0801_with_height_above.json** | N/A | dem_features.ipynb | Project metadata | JSON file containing flood point metadata including Sentinel-1 data availability flags |

#### File Path Configurations
The project supports both Windows and Linux/cluster environments:
- **Windows paths**: `C:\Users\alekb\Downloads\`
- **Linux/Anvil cluster paths**: `/anvil/projects/x-cis250634/team5/`

### Output Data Files (In Repository)

#### `data/` Directory
| File | Size | Generated By | Description |
|------|------|-------------|-------------|
| **imp_surface_features.csv** | 127 KB | NLCD_Extract_v0.1.0.py | NLCD-derived landscape metrics for each flood point including area percentages, core area indices, and impervious surface characteristics |
| **dem_features.csv** | 89 KB | dem_features.ipynb | DEM-derived topographic features including elevation, slope, aspect, and terrain roughness metrics |
| **HWM_Depth_m.csv** | NEW | Calculate_HWM_Depth_v1.0.ipynb | High water mark depth measurements in meters, serving as the target variable for machine learning flood prediction models |


### Feature Columns

#### imp_surface_features.csv
- `ID`: Flood point identifier
- `peak_date`: Original flood event date  
- `nlcd_year`: NLCD data year used for analysis
- `total_area_km2`: Total buffer area in km² (typically 9.1809 km²)
- `pct_area_1`: % of buffer with low-intensity impervious surface (20-49%)
- `pct_area_2`: % of buffer with medium-intensity impervious surface (50-79%)
- `area_km_1`, `area_km_2`: Absolute areas (km²) for each impervious class
- `cai_1`, `cai_2`: Core Area Index (landscape fragmentation metric, higher values indicate less fragmented landscapes)

#### dem_features.csv
- `file_id`: Flood point identifier matching ID in other datasets
- `year`: Year of DEM data used (includes '.tif' extension)
- `dem_min`: Minimum elevation value (meters) within the analysis area
- `dem_max`: Maximum elevation value (meters) within the analysis area
- `dem_mean`: Mean elevation value (meters) within the analysis area
- `dem_iqr`: Interquartile range of elevation values (meters) - measure of topographic variability
- `projection`: Coordinate reference system used (EPSG:4326 - WGS84 geographic)

#### HWM_Depth_m.csv
- `ID`: Flood point identifier matching other datasets
- `Year`: Year of the flood event (integer format)
- `HWMdepth_m`: High water mark depth in meters above ground surface, calculated as (flood elevation - ground elevation from DEM)


## Dependencies

### Core Geospatial Libraries
- `rasterio` - Geospatial raster data I/O and processing, windowed reading, CRS transformations
- `geopandas` - Vector geospatial data handling, shapefile I/O, geometry operations
- `pylandstats` - Landscape ecology metrics calculation (Core Area Index, area percentages)
- `shapely` - Geometric operations, buffer creation, spatial analysis
- `pathlib` - Cross-platform file path handling (Python 3.4+)

### Data Science & ML Libraries  
- `pandas` - Data manipulation, CSV I/O, temporal data parsing
- `numpy` - Numerical computations, array operations, statistical functions
- `scipy` - Statistical functions (interquartile range calculation)
- `torch` - PyTorch deep learning framework for neural networks
- `torch.nn` - Neural network layers and architectures
- `torch.optim` - Optimization algorithms for model training
- `torch.utils.data` - Data loading utilities (DataLoader, TensorDataset)

### Visualization & Progress Libraries
- `matplotlib` - Data visualization, plotting, histograms
- `matplotlib.pyplot` - Plotting interface for visualizations
- `tqdm` - Progress bar displays for long-running processes

### Standard Python Libraries
- `os` - File system operations, path manipulation
- `sys` - System-specific parameters and functions
- `glob` - Unix-style pathname pattern expansion
- `json` - JSON data parsing and manipulation
- `warnings` - Warning control and management
- `datetime` - Date and time manipulation for temporal data


## Notes

### Performance Considerations


### Data Quality Notes
- **Missing Years**: Script automatically uses closest available NLCD year when exact match unavailable
- **Coordinate Systems**: Automatic handling of CRS transformations between geographic and projected coordinates
- **Core Area Index**: Higher values indicate less fragmented landscapes (better habitat connectivity)

### Development Notes
- **File Paths**: Currently configured for Windows environment with alternative Linux paths commented out
- **Version Control**: Major processing steps are logged and versions tracked for reproducibility  
- **Error Logging**: Comprehensive error handling preserves processing continuity for large datasets
- **Modular Design**: Separate modules for routing, training, and feature extraction allow independent development and testing
